{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3286d4a-ffb9-47c2-a2f3-5502a755e7c2",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "#### Author: Michal Kubina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33a8a846-14a6-4603-a966-b2ab28d618be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "686626eb-3644-4418-918c-09541d0e0e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Game of Thrones            15462\n",
       "Breaking Bad                6424\n",
       "Better Call Saul            5268\n",
       "Black Mirror                4720\n",
       "Stranger Things             2891\n",
       "True Detective              2721\n",
       "Twin Peaks                  2399\n",
       "Dark                        2004\n",
       "Ozark                       1417\n",
       "Mr. Robot                   1347\n",
       "Orange is the New Black     1208\n",
       "The Witcher                 1188\n",
       "Fargo                        680\n",
       "Mindhunter                   657\n",
       "The Newsroom                 484\n",
       "Succession                   389\n",
       "The Crown                    338\n",
       "House of Cards               158\n",
       "La Casa de Papel             150\n",
       "The Mandelorian               95\n",
       "Name: title, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Better Call Saul</td>\n",
       "      <td>linear</td>\n",
       "      <td>2017</td>\n",
       "      <td>Walter. And there the chain ends.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Better Call Saul</td>\n",
       "      <td>linear</td>\n",
       "      <td>2016</td>\n",
       "      <td>I love this show. But it's hard to argue again...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              title    type  year  \\\n",
       "0  Better Call Saul  linear  2017   \n",
       "1  Better Call Saul  linear  2016   \n",
       "\n",
       "                                                post  \n",
       "0                  Walter. And there the chain ends.  \n",
       "1  I love this show. But it's hard to argue again...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_pickle(\"discussions.p\")\n",
    "display(data.title.value_counts())\n",
    "display(data.head(2))\n",
    "print(data[data.title == \"Stranger Things\"].year.min())\n",
    "print(data[data.title == \"Stranger Things\"].year.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6dcd17b-70d3-4392-8896-d6e8e613d913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    punctuations = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "    for punctuation in punctuations:\n",
    "        text = text.replace(punctuation, '')\n",
    "    text = text.lower() \n",
    "    text = text.split()\n",
    "    return text\n",
    "\n",
    "def train_word2vec(dims, tokenized_texts):\n",
    "    SIZE = dims # dimensions of the embeddings\n",
    "    SG = 1 # whether to use skip-gram or CBOW (we use skip-gram)\n",
    "    WINDOW = 10 # the window size\n",
    "    N_WORKERS = 8 \n",
    "    MIN_COUNT = 5\n",
    "\n",
    "    model = Word2Vec(size=SIZE,\n",
    "                    sg=SG,\n",
    "                    window=WINDOW, \n",
    "                    min_count=MIN_COUNT,\n",
    "                    workers=N_WORKERS)\n",
    "    model.build_vocab(tokenized_texts)\n",
    "    model.train(tokenized_texts,\n",
    "               total_examples=model.corpus_count,\n",
    "               epochs=model.epochs) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "922718a8-1851-46ea-beff-db16f3ae74a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data[data.title == \"Game of Thrones\"].post.values\n",
    "tokenized_texts = [tokenize(text) for text in texts]\n",
    "model = train_word2vec(300, tokenized_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77e3d324-8489-4a4b-b611-bd0186a16355",
   "metadata": {},
   "outputs": [],
   "source": [
    "got = {}\n",
    "got[\"m\"] = [\"he\", \"his\", \"male\", \"father\", \"king\", \"grandfather\", \"boy\", \"husband\",\n",
    "            \"man\", \"men\", \"son\", \"nephew\", \"jon\", \"tyrion\", \"jaime\", \"bran\", \"ned\",\n",
    "            \"joffrey\", \"theon\", \"samwell\", \"tywin\", \"varys\", \"rob\", \"stannis\", \"davos\"]\n",
    "got[\"f\"] = [\"she\", \"her\", \"female\", \"mother\", \"queen\", \"grandmother\",\"girl\", \"pregnant\",\n",
    "            \"wife\", \"menstruation\", \"femininity\", \"women\", \"woman\", \"daughter\", \"niece\",\n",
    "            \"cersei\", \"daenerys\", \"arya\", \"sansa\", \"melisandra\"]\n",
    "\n",
    "words = [word for word in got[\"m\"] if word in model.wv.vocab] # checks if word is in vocabulary (i.e. has been seen by the model before)\n",
    "mean_embedding_m = np.mean([model.wv[word] for word in words], axis=0)\n",
    "words = [word for word in got[\"f\"] if word in model.wv.vocab] # checks if word is in vocabulary (i.e. has been seen by the model before)\n",
    "mean_embedding_f = np.mean([model.wv[word] for word in words], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f377e82b-e621-4c9d-adad-fe927f84917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = pd.read_pickle(\"word_cats.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1e941bb-a794-4425-b0c1-92cc6c7f60d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/67/d4z6xlfn6c76_0clhpg1p0tc0000gn/T/ipykernel_2648/1366904313.py:9: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  d = pd.Series(dic1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "body         -0.097024\n",
       "family       -0.092944\n",
       "percept      -0.083700\n",
       "social       -0.059061\n",
       "relig        -0.058422\n",
       "negemo       -0.055745\n",
       "affect       -0.045808\n",
       "cogproc      -0.041557\n",
       "leisure      -0.035528\n",
       "posemo       -0.034865\n",
       "occupation   -0.033707\n",
       "money        -0.028332\n",
       "work         -0.024016\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.053131509052789704"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic2 = {}\n",
    "for col in ref.columns:\n",
    "    dic1 = {}\n",
    "    for word in ref[col].values:\n",
    "        if word in model.wv.vocab:\n",
    "            frob_m = np.linalg.norm(np.subtract(model.wv[word], mean_embedding_m))\n",
    "            frob_f = np.linalg.norm(np.subtract(model.wv[word], mean_embedding_f))\n",
    "            dic1[word] = frob_m - frob_f\n",
    "        d = pd.Series(dic1)\n",
    "        dic2[col] = d.mean()\n",
    "display(pd.Series(dic2).sort_values())\n",
    "pd.Series(dic2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b93039b-0fc7-4c47-b337-5d34620721ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
